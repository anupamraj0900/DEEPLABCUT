
1. In general, DeepLabCut’s positioning of markers corresponds to about 60-70% of the objects in my videos and does a good job of positioning its markers to match the moving objects. For videos 1 and 2, the marker type that was used was a full_human from DeepCut’s list of options. Primarily, the positioning of the markers correspond to the subjects and line up with the individual's limbs, hands, feet, face as well as other features on their body. These markers are present when the subject is moving in the video as the software is able to detect and track the subject's movement, shift in body as well as other contortions. However, there are minor mismatches that occur due to errors in the background.
After analyzing both of the videos, I can see that the distance of the object from the camera is the biggest factor to get a clearer and better analysis. I noticed that when the object in my video came closer to the camera the positioning of the markers got better due to closer proximity that could capture a clearer quality image for analysis. The second factor that I realized impacted the software’s ability to position markers with the video was the presence of surrounding objects. For instance, the second video had large objects such as a school bag and chair in its field of view within the background. This was a potential for error as the software assumed these objects to be marker positions. Despite this, the software was still able to accurately detect the moving objects who were walking. Specifically, features such as the walker's legs and arms were detected in both videos of the moving individuals as these were prominent features that were identified and marked better. This implies that the estimation of the walker’s legs and arms were features that were more evident and could be analyzed as well as were readily visible by the software over other body parts. Hence, one of the strengths of DeepLabCut is that it can reliably report whether a body part is visible in a given frame through the identification of its marker positions, which is evident in both screenshots of the videos. This also indicates that DeepLabCut’s positioning of markers is able to focus on features such as shoes as part of its full_human marker type. As well, an object that appears to be marked better than others in the second video was the subject's head as it is marked better than video one. This may be because in video 2, the subject is looking straight up at the camera, so their head is detected by the camera better in that frame as well as closer. This enables the subject's head in video 2 to be marked better as it remains in focus and can be visible seen as it facing upwards.
In general, DeepLabCut’s positioning of markers matches well with what can be seen in the video as they correspond with the movement of the object within the video. However, specific features that are better taken into account are features that are more visible, in a clearer frame, in closer proximity as they can be marked better than other body parts or objects.

2. The quality of analysis for both videos differs slightly due to the way in which the video was captured. When considering this, it can be important to note that there are some clear and situational features that differ in both videos, leading to the difference in the accuracy of these marker positions. As seen, the first video contained more accurate and precise positioning of the markers to the moving object than the second. However, within the second video, there were inaccuracies in the position of the makers as the software inaccurately detected side objects that were in the frame to be markers as they were large, and misled the software. This has to do with the positioning of surrounding objects, as large objects can be detected by the software, which may inaccurately interpret them. Hence, a clear field of view is required for optimal results.
This is clearly shown as the first walker has a greater number of markers that are actually present and accurately marked on the subject's body compared to the second video. The first video also has a greater distribution in the markers as they are more spread apart and precisely marked, representing the individual's feet and arms.. This means that the marker positions covered a greater extent of the subject in video 2 than in Video 1. This can also contribute to the difference in the quality of analysis for both videos as video 1 indicates a stronger quality of analysis since the marker positions cover a greater surface area of the individual.
Additionally, the second walker captured in the video was taller, which meant that the videographer had to walk back a farther distance to be able to capture the entirety of the walker’s body in the frame. This affected the quality of analysis for the videos as the distance of the object from the camera was a significant factor in obtaining a clear image for analysis. This can make it more difficult for DeepLabCut to position markers on the subject as when the subject is positioned farther from the frame, there are no marker labels on them. It was only until 7 seconds later the subject was closer to the frame and the markers appeared. This makes it harder to track and identify the individual. However for video 1, since the subject was shorter in height, the marker positions were more easily identifiable and appeared within the 4 second mark of the video, as she came into closer proximity and were present throughout the entire duration
Furthermore, I noticed that while filming the videos, the subject in video 2 was more confined and restricted with minimal movement as he was moving in a discrete pattern and did not move his arms, hands or face as much when he did so. However, in video 2, the subject is moving her head in multiple directions, and she also swings her arms and hands closer together while she walks. This could have impacted DeepCutLab’s positioning of markers as this creates more movement for the subject in video 2. The subject in video 2 was moving in the same relative position in a straight line following a singular path in the video, which allowed the software to easily analyze this and create marker positions. Hence, the stronger quality of analysis for video 2 is evidenced by the distribution of the marker positions positioned on the subject, the greater number of markers labeled on the individual as well as the frame in which the subject was moving in due to their proximity to the camera.


Furthermore, I noticed that while filming the videos, the subject in video 2 was more confined and restricted with minimal movement as he was moving in a discrete pattern and did not move his arms, hands or face as much when he did so. However, in video 2, the subject is moving her head in multiple directions, and she also swings her arms and hands closer together while she walks. This could have impacted DeepCutLab’s positioning of markers as this creates more movement for the subject in video 2. The subject in video 2 was moving in the same relative position in a straight line following a singular path in the video, which allowed the software to easily analyze this and create marker positions. Hence, the stronger quality of analysis for video 2 is evidenced by the distribution of the<img width="829" alt="Screenshot 2023-01-04 at 6 34 43 PM" src="https://user-images.githubusercontent.com/70150362/210670061-3585e8c5-6b2a-4007-88e7-5c10ab7e7317.png">
<img width="772" alt="Screenshot 2023-01-04 at 6 35 32 PM" src="https://user-images.githubusercontent.com/70150362/210670024-785bc456-d5a5-416c-b0fc-5138524d981e.png">

Furthermore, I noticed that while filming the videos, the subject in video 2 was more confined and restricted with minimal movement as he was moving in a discrete pattern and did not move his arms, hands or face as much when he did so. However, in video 2, the subject is moving her head in multiple directions, and she also swings her arms and hands closer together while she walks. This could have impacted DeepCutLab’s positioning of markers as this creates more movement for the subject in video 2. The subject in video 2 was moving in the same relative position in a straight line following a singular path in the video, which allowed the software to easily analyze this and create marker positions. Hence, the stronger quality of analysis for video 2 is evidenced by the distribution of the![Uploading Screenshot 2023-01-04 at 6.34.43 PM.png…]()
![Uploading Screenshot 2023-01-04 at 6.34.43 PM.png…]()

Furthermore, I noticed that while filming the videos, the subject in video 2 was more confined and restricted with minimal movement as he was moving in a discrete pattern and did not move his arms, hands or face as much when he did so. However, in video 2, the subject is moving her head in multiple directions, and she also swings her arms and hands closer together while she walks. This could have impacted DeepCutLab’s positioning of markers as this creates more movement for the subject in video 2. The subject in video 2 was moving in the same relative position in a straight line following a singular path in the video, which allowed the software to easily analyze this and create marker positions. Hence, the stronger quality of analysis for video 2 is evidenced by the distribution of the![Uploading Screenshot 2023-01-04 at 6.34.43 PM.png…]()
